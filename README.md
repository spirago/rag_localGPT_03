>> ISSUES
* model inference is pretty slow #394
https://github.com/PromtEngineer/localGPT/issues/394
* How to speed up answer time ? #537
https://github.com/PromtEngineer/localGPT/issues/537

>> to start privateGPT:
python ingest.py (--device_type cpu/mps)
python run_localGPT.py --show_sources (--device_type cpu/mps)